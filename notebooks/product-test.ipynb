{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "  CARD                                                     PRICE      STOCK    \n",
      "    \n",
      "  MSI GeForce RTX 5070 Ti 16G INSPIRE 3X OC PLUS | Tarjet  1.109,90€  Agotado  \n",
      "  MSI GeForce RTX 5070 Ti 16G VANGUARD SOC LAUNCH EDITION  1.149,90€  Agotado  \n",
      "  MSI GeForce RTX 5070 Ti 16G GAMING TRIO OC PLUS | Tarje  1.114,90€  Agotado  \n",
      "  MSI GeForce RTX 5070 Ti 16G VENTUS 3X OC | Tarjeta Gráf  889,90€    Agotado  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from columnar import columnar\n",
    "from bs4 import BeautifulSoup\n",
    "from configparser import ConfigParser\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "''' Latest scraping version functions'''\n",
    "async def fetch(url):\n",
    "    async with aiohttp.ClientSession(connector=aiohttp.TCPConnector(ssl=False)) as session:\n",
    "        async with session.get(url) as response:\n",
    "            return await response.text()\n",
    "        \n",
    "async def crawl(parsers, url_type):\n",
    "    output = []\n",
    "\n",
    "    used_tools = {k:v for k,v in parsers.items(url_type)}\n",
    "    \n",
    "    urls = list(used_tools.values())\n",
    "    tools = list(used_tools.keys())\n",
    "    \n",
    "    tasks = [fetch(url) for url in urls]\n",
    "    \n",
    "    html_pages = await asyncio.gather(*tasks)\n",
    "      \n",
    "    for i, html in enumerate(html_pages):\n",
    "        tag_n = eval(parsers['PARSERS'][tools[i] + \"_tag_n\"])\n",
    "        tag_p = eval(parsers['PARSERS'][tools[i] + \"_tag_p\"])\n",
    "        tag_s = eval(parsers['PARSERS'][tools[i] + \"_tag_s\"])\n",
    "        attr_n = eval(parsers['PARSERS'][tools[i] + \"_attr_n\"])\n",
    "        attr_p = eval(parsers['PARSERS'][tools[i] + \"_attr_p\"])\n",
    "        attr_s = eval(parsers['PARSERS'][tools[i] + \"_attr_s\"])\n",
    "\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        name = soup.find_all(tag_n, **attr_n)\n",
    "        price = soup.find_all(tag_p, **attr_p)\n",
    "        stock = soup.find_all(tag_s, **attr_s)\n",
    "        \n",
    "        for j in range(len(name)):\n",
    "            output.append([name[j].get_text().strip()[:55], price[j].get_text().strip(), stock[j].get_text().strip()])\n",
    "\n",
    "        headers = ['card', 'price', 'stock']\n",
    "        table = columnar(output, headers, no_borders=True, max_column_width=None)\n",
    "\n",
    "        print(table)\n",
    "        # print(bcolors.BOLD + name[0].get_text() + bcolors.ENDC)\n",
    "        # print(bcolors.BOLD + price[0].get_text() + bcolors.ENDC)\n",
    "    \n",
    "async def main():  \n",
    "    parsers = ConfigParser(delimiters=(':'))\n",
    "    parsers.read('../parsers.ini')\n",
    "        \n",
    "    '''Getting latest versions from webs'''\n",
    "    await crawl(parsers, 'URLS')\n",
    "        \n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
